{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_array(gen_array, sim_array, cut_array):\n",
    "    \n",
    "    id_particle = ak.to_numpy(gen_array[\"event\"])\n",
    "    id_reco = ak.to_numpy(sim_array[\"event\"])\n",
    "    id_both = ak.to_numpy(cut_array[\"event\"])\n",
    "    print(\"Start masking arrays\")\n",
    "    # Mask out overlapping events\n",
    "    mask_particle_only = ~np.isin(id_particle, id_both)\n",
    "    mask_reco_only = ~np.isin(id_reco, id_both)\n",
    "\n",
    "    particle_only = gen_array[mask_particle_only]\n",
    "    reco_only = sim_array[mask_reco_only]\n",
    "    \n",
    "    particle_only = ak.with_field(particle_only, True, \"pass_particle\")\n",
    "    particle_only = ak.with_field(particle_only, False, \"pass_reco\")\n",
    "\n",
    "    reco_only = ak.with_field(reco_only, False, \"pass_particle\")\n",
    "    reco_only = ak.with_field(reco_only, True, \"pass_reco\")\n",
    "\n",
    "    cut_array = ak.with_field(cut_array, True, \"pass_particle\")\n",
    "    cut_array = ak.with_field(cut_array, True, \"pass_reco\")\n",
    "    \n",
    "    print(\"Done masking\") \n",
    "    \n",
    "    reco_field_order = [\n",
    "    'run', 'event', 'eventWeight',\n",
    "    'ptl1', 'truth_ptl1',\n",
    "    'etal1', 'truth_etal1',\n",
    "    'phil1', 'truth_phil1',\n",
    "    'ptb1', 'truth_ptb1', 'ptb2', 'truth_ptb2',\n",
    "    'ptb3', 'truth_ptb3', 'ptb4', 'truth_ptb4',\n",
    "    'etab1', 'truth_etab1', 'etab2', 'truth_etab2',\n",
    "    'etab3', 'truth_etab3', 'etab4', 'truth_etab4',\n",
    "    'phib1', 'truth_phib1', 'phib2', 'truth_phib2',\n",
    "    'phib3', 'truth_phib3', 'phib4', 'truth_phib4',\n",
    "    'mb1', 'truth_mb1', 'mb2', 'truth_mb2',\n",
    "    'mb3', 'truth_mb3', 'mb4', 'truth_mb4',\n",
    "    'ptj1', 'truth_ptj1', 'ptj2', 'truth_ptj2',\n",
    "    'ptj3', 'truth_ptj3', 'ptj4', 'truth_ptj4',\n",
    "    'ptj5', 'truth_ptj5', 'ptj6', 'truth_ptj6',\n",
    "    'etaj1', 'truth_etaj1', 'etaj2', 'truth_etaj2',\n",
    "    'etaj3', 'truth_etaj3', 'etaj4', 'truth_etaj4',\n",
    "    'etaj5', 'truth_etaj5', 'etaj6', 'truth_etaj6',\n",
    "    'phij1', 'truth_phij1', 'phij2', 'truth_phij2',\n",
    "    'phij3', 'truth_phij3', 'phij4', 'truth_phij4',\n",
    "    'phij5', 'truth_phij5', 'phij6', 'truth_phij6',\n",
    "    'mj1', 'truth_mj1', 'mj2', 'truth_mj2',\n",
    "    'mj3', 'truth_mj3', 'mj4', 'truth_mj4',\n",
    "    'mj5', 'truth_mj5', 'mj6', 'truth_mj6',\n",
    "    'met', 'truth_met', 'metphi', 'truth_metphi',\n",
    "    'ptwhad', 'truth_ptwhad', 'truth_pt_particlewhad',\n",
    "    'rapiditywhad', 'truth_rapidity_particlewhad',\n",
    "    'mwhad', 'truth_mwhad',\n",
    "    'mbl_selected', 'truth_m_particlebl',\n",
    "    'mbwhad_selected', 'truth_m_particlebwhad',\n",
    "    'dRbl_selected', 'truth_dR_particlebl',\n",
    "    'dRbwhad_selected', 'truth_dR_particlebwhad',\n",
    "    'pass_particle', 'pass_reco'\n",
    "    ]\n",
    "\n",
    "    # Fill missing fields with None and keep only listed fields in specified order\n",
    "    def harmonize_array(array, target_fields):\n",
    "        for field in target_fields:\n",
    "            if field not in array.fields:\n",
    "                array = ak.with_field(array, None, field)\n",
    "        return ak.zip({field: array[field] for field in target_fields})\n",
    "    print(\"Start harmonizing fields\")\n",
    "    # Apply harmonization\n",
    "    truth_array = harmonize_array(particle_only, reco_field_order)\n",
    "    cut_array = harmonize_array(cut_array, reco_field_order)\n",
    "    print(\"Done harmonizing\")\n",
    "    df_particle = ak.to_dataframe(particle_only)\n",
    "    df_reco = ak.to_dataframe(reco_only)\n",
    "    df_matched = ak.to_dataframe(cut_array)\n",
    "    print(\"Converted to pandas - Start concatenating\")\n",
    "    # Concatenate\n",
    "    df_final = pd.concat([df_particle, df_reco, df_matched], ignore_index=True)\n",
    "\n",
    "    #final_array = ak.concatenate([particle_only, reco_only, cut_array], axis=0)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ee6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_double_counting(array):\n",
    "    ids = array[\"event\"]\n",
    "\n",
    "    # Use numpy to find unique ones and return indices of the first occurrences\n",
    "    _, unique_index = np.unique(ak.to_numpy(ids), return_index=True)\n",
    "\n",
    "    # Sort indices to preserve original order\n",
    "    unique_index = np.sort(unique_index)\n",
    "\n",
    "    # Select only unique entries\n",
    "    unique_awkward = array[unique_index]\n",
    "    return unique_awkward\n",
    "\n",
    "#truth_array = avoid_double_counting(truth_array)\n",
    "#herwig_array = avoid_double_counting(herwig_array)\n",
    "#pythia_array_reco_cuts = avoid_double_counting(pythia_array_reco_cuts)\n",
    "#pythia_array_matched_cuts = avoid_double_counting(pythia_array_matched_cuts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1482ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Apptainer)",
   "language": "python",
   "name": "apptainer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
